Mnemosyne Core: Подробный архитектурный план реализации подсистемы Tier 2 (The Brain) на Python
1. Исполнительный обзор и архитектурная философия
Проект Mnemosyne Core представляет собой сдвиг парадигмы в области персональной аналитики, переходя от пассивной записи экрана к созданию «Локального цифрового двойника» (Local Digital Twin). Основываясь на критическом анализе и директивах внутреннего CTO, архитектура системы перешла к модели Polyglot V3.0. В этой модели ответственность строго разделена между высокопроизводительным низкоуровневым сборщиком данных («Watcher» на Go) и интеллектуальным аналитическим ядром («Brain» на Python).
Данный отчет детально описывает реализацию Tier 2: The Brain. Это асинхронный аналитический конвейер, задача которого — трансформировать сырой «цифровой выхлоп» (digital exhaust), захватываемый Watcher'ом, в структурированный граф знаний. Реализация на Python обусловлена необходимостью интеграции с обширной экосистемой искусственного интеллекта (PyTorch, HuggingFace, Transformers), которая де-факто является стандартом в индустрии машинного обучения.1
1.1. Операционные императивы и ограничения
Разработка модулей Python диктуется жесткими аппаратными и эксплуатационными ограничениями целевой платформы (NVIDIA RTX 5060 Ti, 80GB System RAM, NVMe SSD).
    • Асинхронность и батчинг: В отличие от Watcher, работающего в реальном времени (5Hz), Brain работает в режиме отложенной обработки (batch processing). Это позволяет нивелировать задержки инференса тяжелых нейросетей.1
    • Управление VRAM: Видеопамять (16 ГБ для RTX 5060 Ti 16GB версии или 8GB для стандартной) является самым дефицитным ресурсом. Архитектура запрещает постоянное удержание VLM (Vision Language Model) в памяти, если пользователь запускает GPU-интенсивные приложения (игры, рендеринг).
    • Приватность (Local-Only): Любая передача данных во внешние облака строго запрещена. Все вычисления, включая OCR и VLM-инференс, должны выполняться локально.
2. Архитектура данных и уровень доступа (DAL)
Фундаментом взаимодействия между Watcher (Go) и Brain (Python) является не сетевой интерфейс, а SQLite база данных, работающая в режиме Write-Ahead Logging (WAL). Это решение обеспечивает надежность и декаплинг (развязку) процессов.
2.1. Конфигурация SQLite для конкурентного доступа
Согласно документации SQLite и анализу производительности, режим WAL позволяет реализовать схему «один писатель, множество читателей» (One Writer, Many Readers).2
Модуль Python должен инициировать соединение с базой данных, строго соблюдая следующие PRAGMA-директивы, чтобы избежать блокировок со стороны Watcher’а:
    • PRAGMA journal_mode = WAL;: Переводит журнал транзакций в режим упреждающей записи. Это позволяет Python-скрипту читать данные из таблицы logs в тот самый момент, когда Go-сервис записывает новые события, без взаимной блокировки.3
    • PRAGMA synchronous = NORMAL;: Снижает частоту вызовов fsync, что критически важно для защиты SSD от износа (Write Amplification) при высокой частоте записи, сохраняя при этом достаточный уровень надежности для десктопного приложения.1
    • PRAGMA temp_store = MEMORY;: Поскольку целевая система обладает 80 ГБ оперативной памяти, все временные таблицы и индексы должны храниться в RAM. Это исключает лишние операции ввода-вывода при сложных аналитических запросах.1
    • PRAGMA busy_timeout = 5000;: Устанавливает тайм-аут ожидания в 5000 мс. Если Watcher выполняет операцию контрольной точки (checkpointing) и эксклюзивно блокирует файл, Python-скрипт должен ждать, а не падать с ошибкой SQLITE_BUSY.2
2.2. Модуль core/dal/sqlite_provider.py
Этот модуль инкапсулирует всю логику работы с базой данных. Использование сырых SQL-запросов в бизнес-логике запрещено. Рекомендуется использование библиотеки aiosqlite для обеспечения асинхронного взаимодействия, что предотвращает блокировку основного событийного цикла Python (Event Loop) во время операций дискового ввода-вывода.6
Ключевые функции модуля:
    1. fetch_pending_events(batch_size=100): Выбирает из таблицы logs записи, которые еще не имеют флага processed. Выборка должна быть ограничена лимитом (batch_size), чтобы не переполнить оперативную память Python-процесса при обработке изображений.
    2. update_event_context(event_id, context_data): Атомарная транзакция для обновления записи. Записывает результаты работы OCR и VLM (текст, описание, теги) в таблицу context.
    3. get_history_tail(timestamp, window_seconds=60): Извлекает исторический контекст («хвост» событий) за последние 60 секунд от текущего события. Это необходимо для LLM, чтобы понимать причинно-следственные связи (например, «пользователь открыл консоль после чтения статьи об ошибке»).1
Схема данных (Schema Design):
Анализ требует наличия виртуальной таблицы FTS5 (Full-Text Search) для быстрого поиска по текстовому контенту. Модуль DAL должен автоматически поддерживать синхронизацию между основной таблицей логов и индексом FTS5 через триггеры или явные обновления.1
3. Системный цикл и управление ресурсами (Guardrails)
Python-подсистема функционирует как демон, управляемый событийным циклом. Однако, учитывая природу "фонового наблюдателя", она должна обладать интеллектом самоограничения.
3.1. Модуль core/system/guardrails.py
Этот модуль реализует механизм «Smart Full Stop».1 Его задача — предотвратить деградацию производительности пользовательских задач (особенно игр). Перед запуском любого тяжелого вычисления (загрузка VLM, OCR всей страницы) система должна пройти проверку.
Алгоритм проверки:
    1. Мониторинг процессов: Использование библиотеки psutil для сканирования активных процессов. Сравнение с «черным списком» (blacklist), содержащим исполняемые файлы популярных игр (напр., cs2.exe, dota2.exe) и ресурсоемких приложений (напр., blender.exe в режиме рендера).
    2. Детекция полноэкранного режима: Использование Win32 API (GetForegroundWindow, GetWindowRect) для определения, запущено ли приложение в эксклюзивном полноэкранном режиме, что является сильным индикатором гейминга или просмотра кино.
    3. VRAM Guard (Защита видеопамяти):
        ◦ Использование библиотеки pynvml (Python bindings for NVIDIA Management Library) для прямого опроса GPU. Команды nvidia-smi через subprocess создают избыточный оверхед (создание нового процесса на каждый запрос) и не рекомендуются для частого опроса.7
        ◦ Логика: Вызов nvmlDeviceGetMemoryInfo. Если свободной видеопамяти менее 4-6 ГБ (минимум для загрузки квантованной MiniCPM-V), цикл обработки немедленно прерывается, и процесс переходит в режим сна (sleep) на длительный интервал (например, 5 минут).10
Пример реализации логики VRAM Guard:

Python


import pynvml

def check_vram_availability(threshold_mb=6000):
    pynvml.nvmlInit()
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
    info = pynvml.nvmlDeviceGetMemoryInfo(handle)
    free_mb = info.free / 1024 / 1024
    pynvml.nvmlShutdown()
    if free_mb < threshold_mb:
        return False
    return True

Этот код демонстрирует прямой доступ к драйверу без парсинга строкового вывода консольных утилит, что является более надежным и быстрым методом.12
4. Модуль восприятия (Perception Layer): Текст и Структура
Согласно стратегии "Context Layer Cake", текстовый сигнал является наиболее информативным и дешевым.1 Система должна отдавать приоритет детерминированным данным (Accessibility Tree) перед вероятностными (OCR).
4.1. Модуль core/perception/text_engine.py (UI Automation)
Для извлечения данных из окон Windows необходимо использовать библиотеку, обеспечивающую доступ к Microsoft UI Automation API.
Выбор библиотеки:
Сравнительный анализ показывает, что библиотека uiautomation (автор yinkaisheng) обеспечивает более полную поддержку современных фреймворков (WPF, UWP, Electron), чем классический бекенд win32 в библиотеке pywinauto.13 pywinauto также поддерживает UIA-бекенд (backend="uia"), но uiautomation часто предоставляет более быстрый и прямой доступ к дереву элементов.14
Архитектурная проблема "Призрачных окон" (Phantom Windows):
События в базу пишутся Watcher'ом в момент $T$, а обработка в Brain происходит в $T + \Delta$. К моменту обработки окно может быть закрыто.
    • Решение: Brain не может полагаться на живое обращение к UI Automation для прошлых событий.
    • Имплементация: В рамках реализации V3.0, Watcher (Go) должен захватывать первичные метаданные (Title). Python модуль text_engine.py используется в двух режимах:
        1. Активный режим (Live): Если задержка $\Delta$ мала (система не нагружена) и окно с указанным HWND все еще существует (win32gui.IsWindow), модуль извлекает полное дерево доступности (Accessibility Tree) для глубокого контекста (названия кнопок, текст в полях ввода).
        2. Пассивный режим (Fallback): Если окно закрыто, модуль полагается только на заголовок окна и OCR скриншота.
Функционал дампа дерева:
Модуль должен уметь обходить дерево элементов, начиная от HWND окна, и сериализовать его в упрощенный JSON (структура: ControlType, Name, Value). Это позволяет LLM "видеть" структуру интерфейса без визуального анализа пикселей.1
4.2. Модуль core/perception/ocr.py (Оптическое распознавание)
OCR является ресурсоемкой операцией и должно применяться выборочно (Tier 3 signal).
Стратегия выбора движка:
    • Tesseract (через pytesseract): Предпочтителен для сценариев, когда GPU занят или VRAM дефицитна. Работает на CPU. Качество ниже на сложных фонах, но достаточно для печатного текста.16
    • EasyOCR / PaddleOCR: Обеспечивают значительно более высокое качество (SOTA), но требуют ресурсов GPU/VRAM. Использование допустимо только если Guardrails подтверждает наличие свободных ресурсов.18
    • Рекомендация: Реализовать гибридный подход. По умолчанию использовать Tesseract для быстрого сканирования. Если Tesseract возвращает "мусор" (низкая уверенность) или если приложение находится в списке "Visual Heavy" (например, демонстрация экрана в Zoom, RDP-сессия), активировать EasyOCR при наличии VRAM.
5. Модуль визуального восприятия (Vision Cortex)
Центральным элементом "понимания" является Vision Language Model (VLM). Документация предписывает использование MiniCPM-V 2.6 (Int4).1
5.1. Модуль core/perception/vision_agent.py
Этот модуль отвечает за загрузку модели, предобработку изображений и генерацию описаний.
Технический стек:
    • Framework: transformers + accelerate + bitsandbytes. Библиотека bitsandbytes критически важна для 4-битного квантования, позволяющего уместить 8-миллиардную модель в 7-8 ГБ VRAM.20
    • Модель: openbmb/MiniCPM-V-2_6-int4.
Оптимизация под 128-битную шину:
Видеокарта RTX 5060 Ti имеет узкую шину памяти (128 бит), что ограничивает пропускную способность (~288 ГБ/с).1 Загрузка весов модели (даже сжатой) занимает ощутимое время (5-15 секунд).
    • Стратегия "Резидентности" (Residency Strategy): Нельзя загружать и выгружать модель для каждого скриншота. Это "убьет" производительность системы из-за thrashing'а шины.
    • План реализации: Обработка должна происходить крупными пакетами.
        1. Накопить, например, 50 событий, требующих визуального анализа (или данные за 10 минут).
        2. Загрузить MiniCPM-V в VRAM.
        3. Выполнить пакетный инференс (Batch Inference) для всех скриншотов.
        4. Выгрузить модель из VRAM (освободить ресурсы для пользователя).
        5. Очистить CUDA кэш (torch.cuda.empty_cache(), gc.collect()).21
Предобработка изображений (Visual Anchor):
Watcher сохраняет полные скриншоты (720p/1080p). Однако интерес представляет только активное окно.
    • Модуль должен использовать библиотеку Pillow (PIL) для обрезки (crop) скриншота по координатам WindowRect, полученным из логов Watcher'а.
    • Это фокусирует внимание VLM на релевантном контенте, повышая точность и снижая количество токенов, затрачиваемых на описание "мусора" (обоев, соседних окон).1
Пример кода инференса:

Python


import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer

def analyze_image(image_path, prompt, model, tokenizer):
    image = Image.open(image_path).convert('RGB')
    msgs = [{'role': 'user', 'content': [image, prompt]}]
    res = model.chat(
        image=None,
        msgs=msgs,
        tokenizer=tokenizer,
        sampling=True,
        temperature=0.7
    )
    return res

Код должен быть обернут в блок try-except для обработки ошибок CUDA OOM (Out Of Memory), с корректным откатом и освобождением памяти.20
6. Модуль когнитивного анализа (Intent Inference)
Этот слой отвечает за семантическую интерпретацию. Он превращает "набор пикселей и кликов" в "человеческое намерение".
6.1. Модуль core/cognition/inference.py
Здесь происходит слияние всех сигналов ("Context Layer Cake") и формирование итогового Markdown-описания.
Конструирование промпта (Prompt Engineering):
CTO требует, чтобы LLM действовала как аналитик, а не писец. Промпт должен быть жестко закодирован (hardcoded system prompt) и включать следующие компоненты:
    1. Визуальное описание: (От MiniCPM-V).
    2. Текстовый контекст: (Заголовок окна + дамп UI Automation / OCR).
    3. Поведенческий маркер: "Input Intensity" (рассчитывается Watcher'ом). Высокая интенсивность в IDE = "Написание кода", низкая в браузере = "Чтение/Исследование".1
    4. История: 3-5 предыдущих событий для установления причинно-следственной связи (Chain of Thought).
Формирование WikiLinks:
Одной из ключевых функций является интеграция в Obsidian через вики-ссылки. Модуль должен анализировать текст на наличие ключевых слов, соответствующих существующим заметкам пользователя (список заметок можно получить, просканировав папку Obsidian Vault).
    • Вход: "User is debugging main.py related to the authentication bug."
    • Выход: "User is debugging [[main.py]] related to the]."
6.2. Модуль core/security/sanitizer.py (PII Redaction)
Перед тем как любой текст попадет в LLM (даже локальную) или будет сохранен в постоянное хранилище (Obsidian), он должен быть очищен от конфиденциальной информации (PII). Это требование безопасности.1
Реализация:
Использование регулярных выражений (Regex) является наиболее эффективным и надежным способом для детерминированного удаления данных.
    • Библиотека: Стандартный модуль re в Python.
    • Паттерны:
        ◦ Email: [a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+
        ◦ IP-адреса: IPv4 и IPv6.
        ◦ Кредитные карты: Простые паттерны для 13-19 цифр (алгоритм Луна может быть избыточен для простой маскировки).
        ◦ API Ключи: Специфические паттерны для популярных сервисов (например, sk-[a-zA-Z0-9]{48} для OpenAI, AKIA[0-9A-Z]{16} для AWS).
    • Процесс: Функция sanitize(text) вызывается для каждого текстового поля (Window Title, OCR result, UIA dump) на ранней стадии обработки. Замещенный текст должен быть явным, например ``.
7. Модуль интеграции (Obsidian Bridge)
Финальный этап — экспорт знаний в пользовательский интерфейс.
7.1. Модуль core/export/obsidian_bridge.py
Этот модуль управляет файловой системой хранилища Obsidian.
Логика работы:
    1. Определение пути: Чтение конфигурации для нахождения корня Vault.
    2. Ротация файлов: Mnemosyne пишет в "Ежедневную заметку" (Daily Note). Модуль должен генерировать имя файла на основе текущей даты (формат YYYY-MM-DD.md).
    3. Атомарная запись: Поскольку пользователь может держать этот файл открытым в Obsidian, запись должна производиться в режиме append (a+ encoding='utf-8'). Рекомендуется делать принудительный сброс буфера (flush, os.fsync), чтобы данные гарантированно оказались на диске и Obsidian мог подхватить изменения (hot reload).
8. Итоговая архитектурная схема (Python Subsystem)
Вся логика собирается в единый пайплайн в файле main.py.
    1. Инициализация: Загрузка конфигов, проверка зависимостей, инициализация sqlite_provider (с WAL-настройками).
    2. Event Loop (Бесконечный цикл):
        ◦ Шаг 1: Guard check. Вызов guardrails.is_safe_to_run(). Если вернул False (игра, мало VRAM) -> time.sleep(60) и переход в начало цикла.
        ◦ Шаг 2: Fetch. Запрос пакета необработанных событий из БД (fetch_pending_events). Если событий нет -> time.sleep(5).
        ◦ Шаг 3: Load Models. Если есть события, требующие VLM, и VRAM свободна -> загрузка MiniCPM-V (иначе пропуск визуального шага).
        ◦ Шаг 4: Batch Processing. Итерация по событиям:
            ▪ sanitizer.clean(window_title)
            ▪ text_engine.extract_context(hwnd) (если окно живо) ИЛИ ocr.process(screenshot)
            ▪ vision_agent.describe(screenshot) (с использованием VLM)
            ▪ inference.synthesize(context) (формирование Intent)
        ◦ Шаг 5: Unload Models. Выгрузка тяжелых моделей для освобождения ресурсов.
        ◦ Шаг 6: Export. Запись результатов в Obsidian (obsidian_bridge.append).
        ◦ Шаг 7: Commit. Пометка событий как processed в БД.
Заключение по реализации
Данный план реализует надежную, приватную и ресурсоэффективную систему. Использование SQLite WAL обеспечивает безопасную асинхронность между Go и Python. Стратегия VRAM Guard и пакетной обработки позволяет использовать мощные модели (MiniCPM-V) на потребительском железе без ущерба для UX. Приоритет Accessibility Tree над OCR и жесткие правила PII Sanitization гарантируют точность и безопасность данных цифрового двойника.
