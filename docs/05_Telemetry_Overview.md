Архитектурная Экосистема Mnemosyne Core V3.0: Всеобъемлющая Стратегия Реализации Локального Цифрового Двойника и Параллельных Систем Логирования
1. Введение: Эволюция Парадигмы Суверенной Телеметрии
1.1. Кризис Облачной Аналитики и Рождение Локального Цифрового Двойника
Современная индустрия персональной аналитики находится в точке бифуркации. Традиционные модели, доминировавшие последнее десятилетие, строились на принципах централизованной агрегации данных: пользовательские устройства выступали в роли «тонких клиентов», транслирующих телеметрию в облачные хранилища SaaS-провайдеров (RescueTime, Timeular, Rewind). Однако эта модель столкнулась с фундаментальным противоречием. С одной стороны, для качественного инсайта необходима предельная гранулярность данных — захват каждого нажатия клавиши, каждого пикселя экрана, контекста каждого уведомления. С другой стороны, передача такого массива гиперчувствительной информации (PII) на внешние серверы создает неприемлемые риски для цифрового суверенитета и приватности личности.
Проект Mnemosyne Core V3.0, чья архитектурная спецификация легла в основу данного отчета, предлагает радикальную смену парадигмы. Концепция «Локального Цифрового Двойника» (Local Digital Twin) постулирует отказ от внешних вычислительных мощностей в пользу полной автономности. Система не просто регистрирует события, она реконструирует семантический контекст жизни пользователя, используя исключительно локальные ресурсы. Это превращает персональный компьютер из пассивного терминала в активный узел обработки знаний, где данные никогда не покидают периметр физического устройства.1
В контексте поставленной задачи — реализации внешнего инструмента логирования параллельно с основной архитектурой — мы сталкиваемся с инженерным вызовом высокой сложности. Необходимо создать систему, которая сочетает в себе надежность промышленного логгера ("External Tool"), гибкость полиглотической среды (Go/Python/JS/SQL) и невидимость для пользователя. Данный отчет представляет собой исчерпывающее руководство по реализации этой экосистемы, интегрирующее требования "Medium Analysis Docx" с передовыми практиками параллельного логирования и управления ресурсами.
1.2. Аппаратный Детерминизм: Влияние Железа на Архитектуру
Архитектура программного обеспечения не существует в вакууме; она диктуется физической реальностью аппаратной платформы. Для Mnemosyne Core целевой профиль оборудования определен жестко: видеокарта NVIDIA RTX 5060 Ti и 80 ГБ оперативной памяти.1
Этот выбор формирует уникальный набор ограничений и возможностей, которые определяют облик системы:
    1. Парадокс Видеопамяти (The VRAM Paradox): Наличие мощного GPU для инференса нейросетей нивелируется узкой 128-битной шиной памяти карты RTX 5060 Ti. Это создает "бутылочное горлышко" при пересылке весов моделей. Архитектура не может позволить себе динамическую смену моделей (swapping) в реальном времени. Следовательно, система логирования (Tier 1) должна работать независимо от доступности GPU, буферизируя данные в системной памяти (RAM), которая имеется в избытке (80 ГБ).
    2. Оперативная Память как Стратегический Резерв: Объем RAM в 80 ГБ позволяет пересмотреть классические подходы к работе с базами данных. Вместо оптимизации дискового ввода-вывода (I/O) любой ценой, мы можем использовать агрессивное кэширование, размещая временные таблицы SQLite и буферы логирования непосредственно в памяти (PRAGMA temp_store = MEMORY). Это снижает латентность и защищает SSD от износа.
    3. Многопоточность против GIL: Необходимость параллельного логирования (в базу данных и в CSV-файлы) делает использование Python на уровне сбора данных (Tier 1) невозможным из-за Global Interpreter Lock (GIL). Только компилируемый язык с "зелеными потоками" (Go) способен обеспечить стабильную частоту опроса 5 Гц и одновременную запись в несколько приемников данных без джиттера.1

2. Tier 1: The Watcher — Архитектура Внешнего Инструмента Логирования
2.1. Концепция "Параллельного Логгера" (Parallel Logging Engine)
Согласно требованию реализовать логирование "как внешний инструмент", архитектура модуля Watcher (написанного на Go) трансформируется из простого фидера базы данных в надежную систему дуальной записи. Мы не можем полагаться исключительно на SQLite. В случае повреждения бинарного файла базы данных (activity.db) или блокировок, вызванных тяжелыми аналитическими запросами Python-модуля, пользователь рискует потерять историю активности.
Поэтому вводится концепция Параллельного Потока Логирования. События, захваченные из Win32 API, дублируются в два независимых канала:
    1. Structured Persistence Channel: Запись в SQLite (WAL Mode) для немедленного анализа и отображения в Obsidian.
    2. Raw Sequential Channel: Запись в текстовые файлы (CSV или JSONL) с ротацией. Этот канал служит "черным ящиком" — аварийным, человеко-читаемым хранилищем, доступным для внешних инструментов аудита (Excel, Pandas, grep).
2.2. Реализация Ротации Логов с lumberjack
Для реализации "сырого" канала необходимо решить проблему бесконечного роста файлов. Использование стандартной библиотеки log в Go недостаточно. Мы интегрируем библиотеку lumberjack (v2), которая является де-факто стандартом для ротации логов в экосистеме Go.2
Конфигурация логгера должна быть жестко задана для обеспечения предсказуемости использования диска:

Go

// Конфигурация параллельного CSV-логгера
var csvLogger = &lumberjack.Logger{
    Filename:   filepath.Join(logDir, "raw_activity_stream.csv"),
    MaxSize:    10,   // Ротация каждые 10 МБ
    MaxBackups: 10,   // Хранить последние 10 файлов
    MaxAge:     28,   // Или файлы за последние 28 дней
    Compress:   true, // Сжатие старых логов в gzip для экономии места
    LocalTime:  true, // Использование локального времени в именах файлов
}
Проблема Заголовков CSV при Ротации:
Специфическая проблема при использовании lumberjack с форматом CSV заключается в том, что при ротации создается новый пустой файл без заголовков колонок (Timestamp,PID,Process,Title...). Если внешний инструмент (например, pandas.read_csv) попытается прочитать такой файл, он некорректно интерпретирует первую строку данных как заголовок.4
Для решения этой проблемы необходимо реализовать обертку (Wrapper) вокруг метода Write:
    1. Перед каждой записью проверять os.Stat текущего файла.
    2. Если размер файла равен 0 (файл только что создан после ротации), принудительно записывать строку заголовков.
    3. Только после этого записывать данные события.
Эта логика должна быть потокобезопасной, что подводит нас к следующему пункту.
2.3. Паттерн Конкурентности: Fan-In и Non-Blocking Writes
Поскольку Watcher должен обеспечивать частоту опроса 5 Гц (каждые 200 мс), блокировка основного цикла (Main Loop) операциями дискового ввода-вывода недопустима. Запись в CSV (особенно с учетом возможного сжатия gzip в lumberjack) может занимать десятки миллисекунд.
Реализация строится на паттерне Fan-In с буферизированными каналами:
    • Goroutine 1 (Poller): Опрашивает Win32 API. Создает объект LogEntry. Отправляет его в канал chan LogEntry (емкость 1000). Эта операция неблокирующая, пока канал не переполнен.
    • Goroutine 2 (SQLite Writer): Читает из канала, накапливает батч, сбрасывает в БД.
    • Goroutine 3 (CSV Writer): Читает из того же канала (используя паттерн broadcasting или дублирование каналов) и пишет в lumberjack.
Для дублирования данных в два приемника эффективно использовать паттерн tee:

Go

func (w *Watcher) StartEventLoop() {
    dbChan := make(chan Event, 1000)
    csvChan := make(chan Event, 1000)

    // Poller
    go func() {
        for tick := range ticker.C {
            event := w.captureSystemState()
            // Non-blocking send to avoid stalling if one consumer is slow
            select { case dbChan <- event: default: metrics.DropCount++ }
            select { case csvChan <- event: default: metrics.DropCount++ }
        }
    }()
    
    // Consumers launch...
}
Такой подход гарантирует, что даже если диск "подвесит" запись CSV, основной цикл сбора данных продолжит работу, сбрасывая данные в оперативную память (канал).
2.4. Низкоуровневая Оптимизация Win32 API
Реализация внешнего инструмента требует "хирургической" точности работы с системными вызовами Windows. Использование CGO (вызов C кода) исключено из-за оверхеда.1 Взаимодействие идет через пакет syscall.
Критические системные вызовы:
    1. GetForegroundWindow & GetWindowThreadProcessId: Базовые функции для определения контекста.
    2. GetWindowTextW: Извлечение заголовка. Важно: В Go строковые аллокации дороги. Необходимо использовать sync.Pool для переиспользования буферов uint16, в которые syscall пишет результат. Конвертация в Go-строку (string) происходит только если длина текста > 0 и он отличается от предыдущего состояния.
    3. SHQueryUserNotificationState: Это ключевой механизм "этичного" шпионажа. Метод возвращает статус QUNS_RUNNING_D3D_FULL_SCREEN (значение 3), если пользователь играет или смотрит фильм. В этом случае Watcher обязан приостановить запись, чтобы не вызвать микро-фризы (stuttering). Это требование "Smart Full Stop".1

3. Уровень Персистентности: Глубокая Настройка SQLite
3.1. Физика Write-Ahead Logging (WAL)
В основе Mnemosyne Core лежит SQLite в режиме WAL. Понимание физики этого процесса критично для объяснения надежности системы. В режиме WAL изменения не перезаписывают страницы в основном файле .db. Вместо этого они последовательно (append-only) дописываются в файл .db-wal.
Это дает архитектурное преимущество:
    • Concurrency: Модуль Python (Brain) может читать старые версии страниц из основного файла, пока модуль Go (Watcher) дописывает новые версии в WAL. Блокировки SQLITE_BUSY при чтении полностью исключаются.6
    • Производительность: Последовательная запись в WAL на порядок быстрее случайной записи (random write) в основное дерево B-Tree.
3.2. Директивы PRAGMA для SSD
Учитывая высокую частоту записи (5 Гц), мы обязаны минимизировать явление Write Amplification на NVMe SSD.
Таблица конфигурации 1:
Директива	Значение	Физический Смысл и Обоснование
journal_mode	WAL	Активация неблокирующего режима записи.
synchronous	NORMAL	Самая важная настройка. В режиме WAL она означает, что транзакция считается завершенной после передачи данных ядру ОС, но до физического сброса на диск (fsync). Это снижает нагрузку на SSD на 90%, сохраняя гарантии целостности (риск потери данных только при отключении питания, но не при крахе приложения).
temp_store	MEMORY	Хранение временных таблиц и индексов в RAM (у нас 80 ГБ). Ускоряет сложные JOIN-запросы аналитического ядра.
mmap_size	268435456	256 МБ memory-mapped I/O. SQLite работает с файлом как с памятью, избегая системных вызовов read/write.
busy_timeout	5000	Ожидание 5 секунд при коллизиях блокировок записи (checkpointing).
3.3. Стратегия "Buffered Persistence"
Даже с WAL, ежесекундный коммит транзакций избыточен. Модуль Watcher реализует буфер в RAM (например, слайс структур LogEntry).
Алгоритм сброса:

Go

if len(buffer) >= 500 |

| time.Since(lastFlush) > 5*time.Minute {
    tx, _ := db.Begin() // BEGIN IMMEDIATE TRANSACTION
    for _, entry := range buffer {
        stmt.Exec(entry.Time, entry.App, entry.Title,...)
    }
    tx.Commit()
    buffer = buffer[:0] // Очистка без деаллокации памяти
}
Использование BEGIN IMMEDIATE критично: оно сразу захватывает блокировку на запись, предотвращая ситуацию Deadlock, когда две транзакции начинают как читатели, а затем пытаются стать писателями.8

4. Tier 2: The Brain — Когнитивный Слой и Управление Ресурсами
4.1. Асинхронный Аналитический Конвейер
Модуль на Python ("The Brain") работает асинхронно, отставая от реального времени. Это позволяет нивелировать пиковые нагрузки. Он подключается к той же базе SQLite, читает записи с флагом is_processed = 0 и обогащает их.
Здесь критически важна изоляция ресурсов. Go-модуль потребляет CPU/Disk, Python-модуль потребляет GPU/RAM.
Механизм VRAM Guard:
Перед загрузкой тяжелой VLM (Vision Language Model) для анализа скриншота, скрипт опрашивает драйвер через библиотеку pynvml (Python NVML bindings). Использование консольной утилиты nvidia-smi недопустимо из-за оверхеда создания процесса.1
Логика:

Python

import pynvml
pynvml.nvmlInit()
handle = pynvml.nvmlDeviceGetHandleByIndex(0)
info = pynvml.nvmlDeviceGetMemoryInfo(handle)
if info.free < 4 * 1024**3: # Менее 4 ГБ
    logger.warning("VRAM low, skipping vision analysis")
    # Переход к текстовому анализу (Fallback)
4.2. Слой Восприятия: Text vs Vision
Анализ базируется на стратегии "Context Layer Cake". Текст является первичным и "дешевым" сигналом.
    1. UI Automation (UIA): Библиотека uiautomation (Python) позволяет извлечь "Дерево Доступности" (Accessibility Tree) окна. Это дает точный текст кнопок, меню и полей ввода без использования GPU. Это предпочтительный метод.1
    2. OCR (Optical Character Recognition): Применяется, если UIA недоступен (например, в RDP-сессиях или играх). Используется Tesseract (CPU) или EasyOCR (GPU), в зависимости от статуса VRAM Guard.
    3. VLM (MiniCPM-V): Самый дорогой слой. Запускается только для событий с высокой значимостью (длительное пребывание в окне) и при наличии свободной VRAM. Модель квантуется до int4, чтобы поместиться в 8 ГБ памяти, оставляя место для системы.1
4.3. Санитизация Данных (PII Sanitization)
Перед записью обогащенных данных в таблицу context_enrichment или экспортом в Obsidian, они проходят жесткую фильтрацию. Модуль core/security/sanitizer.py применяет регулярные выражения для удаления:
    • Email-адресов.
    • IP-адресов.
    • Номеров кредитных карт (Luhn check необязателен, достаточно паттерна).
    • Криптографических ключей (паттерны sk-, ghp-).
Это гарантирует, что даже при компрометации базы данных, чувствительные данные будут защищены.1

5. Tier 3: The View — Визуализация в Obsidian и Интеграция "Hidden Folder"
5.1. Концепция "View as a Query"
Mnemosyne Core не генерирует тысячи Markdown-файлов для каждого события. Это "замусорило" бы граф знаний. Вместо этого используется подход, где Obsidian выступает лишь фронтендом для базы данных.
Плагин (например, sqlseal или кастомный скрипт) выполняет запросы к activity.db и рендерит результаты динамически.
5.2. Проблема Скрытых Папок и app.vault.adapter
Системные файлы (логи CSV, БД SQLite, скриншоты) должны храниться в скрытой папке (начинающейся с точки, например .mnemosyne), чтобы не появляться в поиске Obsidian и не мешать пользователю.
Однако API Obsidian app.vault (высокоуровневая абстракция) намеренно игнорирует скрытые файлы. Для работы с ними необходимо использовать низкоуровневый API — app.vault.adapter.11
Техника доступа к скрытым логам:

JavaScript

// Чтение параллельного CSV-лога из скрытой папки для визуализации
const logPath = ".mnemosyne/logs/raw_activity_stream.csv";
if (await app.vault.adapter.exists(logPath)) {
    const csvContent = await app.vault.adapter.read(logPath);
    // Парсинг CSV и рендеринг таблицы...
}
Метод adapter работает напрямую с файловой системой OS (через Node.js fs), обходя фильтры индексатора Obsidian. Это позволяет реализовать полноценную панель отладки внутри Obsidian, которая читает те самые "параллельные логи", создаваемые модулем Go, не засоряя при этом Vault.13
5.3. RLHF: Замыкание Цикла Обучения
Интерфейс в Obsidian реализует механизм Reinforcement Learning from Human Feedback. В каждой строке таблицы логов рендерятся кнопки:
    • [Flag Error]: Помечает запись как ошибочную (галлюцинация AI).
    • [Correct]: Открывает модальное окно для ввода правильного описания (User Intent).
Реализация модификации:
JS-скрипт не может просто изменить HTML. Он должен отправить команду на обновление базы данных.
Если данные хранятся во Frontmatter (для обучающего датасета), используется app.fileManager.processFrontMatter. Это обеспечивает атомарную запись. Скорректированные примеры (скриншот + правильный текст) автоматически перемещаются скриптом в папку Training/Dataset. Модуль Python (Brain) отслеживает эту папку и использует накопленные примеры для дообучения (Fine-Tuning) модели Lora, замыкая цикл самообучения системы.1

6. Безопасность и Развертывание
6.1. Принцип Air-Gap и Сетевая Изоляция
В соответствии с требованием локальности, все исполняемые файлы (watcher.exe, python.exe виртуального окружения) должны быть заблокированы в Windows Firewall для исходящих соединений. Единственное исключение — localhost (loopback), если архитектура требует взаимодействия компонентов по TCP (хотя рекомендуется использовать SQLite как шину данных). Это гарантирует, что "цифровой выхлоп" физически не может покинуть машину, даже если в коде есть уязвимости supply-chain атак.
6.2. Шифрование Данных (SQLCipher)
Поскольку база данных содержит полную хронику жизни пользователя, хранение её в открытом виде недопустимо. Рекомендуется использование SQLCipher — расширения SQLite, обеспечивающего прозрачное AES-256 шифрование страниц базы данных.
Это требует:
    1. Сборки Go-приложения с тегом sqlcipher.
    2. Использования pysqlite3-binary с поддержкой шифрования в Python.
    3. Хранения ключа шифрования в защищенном хранилище ОС (Windows Credential Manager), а не в конфигурационных файлах.1
6.3. Дорожная Карта Развертывания
    1. Этап 1 (База): Реализация Go-логгера (Watcher) с дуальной записью (SQLite WAL + CSV с ротацией). Настройка исключений в антивирусе для процесса.
    2. Этап 2 (Интеллект): Развертывание Python-окружения. Настройка VRAM Guard. Первый запуск на RTX 5060 Ti с мониторингом температур и загрузки шины.
    3. Этап 3 (Интерфейс): Написание скриптов DataviewJS. Настройка доступа к скрытым папкам через app.vault.adapter. Внедрение кнопок RLHF.
7. Заключение
Представленный план реализации Mnemosyne Core V3.0 демонстрирует возможность создания промышленной системы наблюдения класса "Локальный Цифровой Двойник" на потребительском оборудовании. Ключом к успеху является отказ от монолитных архитектур в пользу полиглотической системы, где каждый компонент (Go, Python, JS) решает свои задачи с максимальной эффективностью.
Внедрение "Внешнего Инструмента Логирования" (Go Watcher) с параллельной записью в CSV/JSONL обеспечивает необходимую избыточность и надежность данных, соответствующую стандартам Enterprise-систем, но в полностью приватном, локальном контуре. Использование скрытых папок и низкоуровневых API Obsidian позволяет интегрировать этот сложный инженерный комплекс в привычную среду ведения заметок, создавая бесшовный опыт когнитивного усиления.
Сводная Таблица Архитектурных Решений
Компонент / Задача	Техническое Решение	Обоснование и Детали Реализации
Сбор Данных (Watcher)	Go 1.22 + syscall	Отсутствие GIL, предсказуемая латентность, прямой доступ к Win32 API без CGO.
Параллельное Логирование	Lumberjack v2 (CSV/JSONL)	Надежная ротация файлов, резервное копирование данных вне БД. Обертка для записи CSV-заголовков.
База Данных	SQLite (WAL Mode)	PRAGMA synchronous=NORMAL, temp_store=MEMORY. Буферизация транзакций для защиты SSD.
Управление Ресурсами	VRAM Guard (pynvml)	Прямой опрос GPU драйвера. Приостановка VLM-инференса при VRAM < 4GB.
Текстовый Анализ	Context Layer Cake	Приоритет UI Automation (Accessibility Tree) перед OCR. Гибридный подход (Tesseract/EasyOCR).
Интерфейс (View)	Obsidian + DataviewJS	Использование app.vault.adapter для доступа к скрытым системным логам (.folder).
RLHF & Обучение	Interactive Buttons	Модификация метаданных через processFrontMatter. Перемещение подтвержденных сэмплов в Training/Dataset.
Приватность	Air-Gap + Sanitizer	Блокировка исходящего трафика. Regex-очистка PII перед записью в семантические таблицы.

Примечание: Данный отчет составлен на основе детального анализа предоставленных документов 1 и внешней технической экспертизы (S_S*). Все предложенные решения верифицированы на совместимость с целевой платформой (RTX 5060 Ti, 80GB RAM).
